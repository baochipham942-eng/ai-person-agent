# AI Person Agent (AI ‰∫∫Áâ©Â∫ì)

## Project Overview
A full-stack web application that aggregates, enriches, and presents comprehensive profiles of influential figures in the AI industry. Combines data from multiple sources (Wikidata, Exa.ai, GitHub, YouTube, X/Twitter) with AI-powered data cleaning to build a high-quality AI professional database.

## Tech Stack

### Frontend
- **Next.js 16.1.1** with App Router
- **React 19** + **TypeScript 5**
- **TailwindCSS 4** + **Arco Design 2.66**
- React Markdown for content rendering

### Backend
- **Next.js API Routes** (serverless)
- **NextAuth 5.0.0-beta.30** (Credentials provider)
- **Prisma ORM 5.22** with PostgreSQL
- **Neon Serverless** (WebSocket driver for fast cold starts)

### AI Integration
- **DeepSeek** - text extraction, data cleaning, JSON generation
- **Perplexity API** - complex structured data extraction
- **OpenAI** - fallback LLM
- **AI SDK 6.0.3** - unified LLM interface

### Data Sources
- Wikidata (identity, metadata)
- Exa.ai (web search, links)
- Grok/X.AI (Twitter data)
- GitHub API, YouTube Data API
- OpenAlex (academic data)

### Infrastructure
- **Vercel** - frontend/API hosting
- **Aliyun FC** - China reverse proxy
- **Inngest** - background job orchestration

## Project Structure
```
app/                    # Next.js App Router
  api/                  # API routes (admin, auth, person, search, inngest)
  (main)/               # Main layout group
  person/               # Person detail pages
lib/
  datasources/          # Multi-source integrations (wikidata, exa, grok, github, youtube)
  inngest/              # Background job workflows
  agents/               # AI agents (qa, router)
  ai/                   # DeepSeek wrapper, prompts, translators
  utils/                # Identity verification, avatar, quality scoring
  db/prisma.ts          # Singleton Prisma client (WebSocket pool)
scripts/
  enrich/               # Data enrichment pipelines (recrawl_robust, trigger_content_fetch)
  tools/                # CSV export, deduplication, cleanup
  audit/                # Data quality verification
prisma/schema.prisma    # Database models
```

## Package Manager
**Always use `bun` instead of npm/pnpm/yarn.**

## Key Commands
```bash
# Development
bun install
bun dev                     # Start dev server (port 4001)
bun dev:inngest             # Start with Inngest local dev
bun dev:all                 # Run both concurrently

# Database
bun db:generate             # Generate Prisma client
bun db:migrate              # Apply migrations
bun db:push                 # Push schema to Neon
bun db:studio               # Open Prisma Studio

# Build & Deploy
bun run build               # Production build
bun start                   # Start production (port 4001)
bun run deploy:build        # Build with asset copying for FC

# Data Scripts
bun scripts/enrich/recrawl_robust.ts         # Core person enrichment
bun scripts/enrich/trigger_content_fetch.ts  # Update GitHub/YouTube content
bun scripts/tools/export_people_csv.ts       # Export to CSV
```

## Environment Variables
```bash
DATABASE_URL=               # Neon Postgres pooler URL (with -pooler suffix)
DIRECT_URL=                 # Neon direct URL (without -pooler, for Prisma CLI)
DEEPSEEK_API_KEY=           # LLM for data cleaning
DEEPSEEK_API_URL=           # DeepSeek endpoint
EXA_API_KEY=                # Web search
GOOGLE_API_KEY=             # YouTube Data API
PERPLEXITY_API_KEY=         # Complex Q&A
INNGEST_EVENT_KEY=          # Background jobs
XAI_API_KEY=                # Grok API
XAI_BASE_URL=               # Grok endpoint
AUTH_SECRET=                # NextAuth secret
OPENAI_API_KEY=             # (Optional) fallback
```

## Key Database Models
- **People** - profiles with QID (Wikidata ID), bio, scores, status
- **PersonRole** - career history with organizations and dates
- **Organization** - companies, universities, linked to Wikidata
- **Card** - content cards (achievements, news, research)
- **RawPoolItem** - raw content from GitHub, YouTube, blogs

## Core Workflows

### Person Enrichment (`scripts/enrich/recrawl_robust.ts`)
1. Search Wikidata for identity (QID, aliases)
2. Fetch career history with dates
3. Find official links via Exa.ai
4. Extract X/Twitter via Grok
5. Merge sources, create PersonRole/Organization records

### Content Updates (`scripts/enrich/trigger_content_fetch.ts`)
- 7-day cycle per source
- GitHub: Top 10 recent repos
- YouTube: Latest 10 videos
- Blog: RSS/web via Exa

### Identity Verification (`lib/utils/identity-verifier.ts`)
- Multi-signal scoring (0-1.0)
- +0.4 QID match, +0.15 org match, +0.1 keywords
- Threshold < 0.5 = rejected

## Deployment Notes
- **Vercel**: Frontend/API hosting
- **Aliyun FC**: Use `s deploy -y --use-remote` (preserves HTTPS)
- **Neon WebSocket**: 4s ‚Üí 300ms cold start optimization
- **NextAuth**: Requires `trustHost: true` for proxy

## Neon Database Connection

### ËøûÊé•ÈÖçÁΩÆ
- **DATABASE_URL**: pooler ËøûÊé•ÔºåÂ∏¶ `-pooler` ÂêéÁºÄÔºåÂ∫îÁî®ËøêË°åÊó∂‰ΩøÁî®
- **DIRECT_URL**: Áõ¥ËøûÔºåÊó† `-pooler`ÔºåPrisma CLI (`db push`, `migrate`) ‰ΩøÁî®

### Â∏∏ËßÅÈóÆÈ¢ò

**ÈóÆÈ¢ò**: `prisma db push` Êä•Èîô `Can't reach database server`
**ÂéüÂõ†**: Neon ÂÖçË¥πÁâàÈó≤ÁΩÆÂêé‰ºöÊöÇÂÅúÔºåÁõ¥ËøûÂèØËÉΩË∂ÖÊó∂
**Ëß£ÂÜ≥**:
1. ÂÖàËøêË°å‰ªªÊÑèËÑöÊú¨Âî§ÈÜíÊï∞ÊçÆÂ∫ì: `npx tsx -e "import {prisma} from './lib/db/prisma'; prisma.people.count().then(console.log)"`
2. ÂÜçËøêË°å `npx prisma db push`
3. Â¶Ç‰ªçÂ§±Ë¥•ÔºåÁî® raw SQL Ê∑ªÂä†Â≠óÊÆµ: `prisma.$executeRawUnsafe('ALTER TABLE "People" ADD COLUMN IF NOT EXISTS "fieldName" TEXT')`

**ÈóÆÈ¢ò**: ËÑöÊú¨‰∏≠ÈÄî `PrismaClientKnownRequestError` ËøûÊé•Êñ≠ÂºÄ
**ÂéüÂõ†**: ÁΩëÁªúÊ≥¢Âä®Êàñ Neon ËøûÊé•Ê±†ÂõûÊî∂
**Ëß£ÂÜ≥**: ËÑöÊú¨Â∑≤‰ΩøÁî® WebSocket ËøûÊé•Ê±†ÔºåÈÄöÂ∏∏‰ºöËá™Âä®ÈáçËøû„ÄÇÂ¶ÇÊåÅÁª≠Â§±Ë¥•ÔºåÁ≠âÂæÖÂá†ÁßíÈáçËØï„ÄÇ

### Êñ∞Â¢û‰∫∫Áâ©ÂÖ•Â∫ìÊµÅÁ®ã
```bash
# 1. ÁºñËæë scripts/enrich/add_priority_ai_people.ts Ê∑ªÂä†‰∫∫Áâ©Êï∞ÊçÆ
# 2. ËøêË°åÂÖ•Â∫ì
npx tsx scripts/enrich/add_priority_ai_people.ts

# 3. Êï∞ÊçÆË°•ÂÖ®
npx tsx scripts/enrich/recrawl_robust.ts           # ËÅå‰∏öÂéÜÂè≤
npx tsx scripts/enrich/enrich_openalex.ts          # Â≠¶ÊúØÂºïÁî®
npx tsx scripts/enrich/enrich_topics_highlights.ts # ËØùÈ¢òÊ†áÁ≠æ
npx tsx scripts/fix_missing_avatars.ts             # Â§¥ÂÉè
```

## MCP Tools ‰ºòÂÖàÁ∫ß

ÂΩìÊâßË°å‰ª•‰∏ã‰ªªÂä°Êó∂Ôºå**ÂøÖÈ°ª‰ºòÂÖà‰ΩøÁî® MCP tools** ËÄåÈùûÁºñÂÜôËÑöÊú¨Ôºö

| ‰ªªÂä°Á±ªÂûã | MCP Tool | ÂõûÈÄÄÊñπÊ°à |
|---------|----------|---------|
| Êï∞ÊçÆÂ∫ìÊü•ËØ¢/ÁªüËÆ° | `mcp__postgres__query` | Prisma ËÑöÊú¨ |
| Web ÊêúÁ¥¢ | `mcp__exa__web_search_exa` | lib/datasources/exa.ts |
| ‰ª£Á†ÅÊêúÁ¥¢ | `mcp__exa__get_code_context_exa` | Grep |
| ÁΩëÈ°µÊäìÂèñ | `mcp__firecrawl__firecrawl_scrape` | WebFetch |
| ÁΩëÁ´ôÂú∞Âõæ | `mcp__firecrawl__firecrawl_map` | ÊâãÂä®Êé¢Á¥¢ |
| GitHub PR/Issue | `mcp__github__*` | gh CLI |
| Êñá‰ª∂Êìç‰Ωú | `mcp__filesystem__*` | Read/Write |
| ÊµèËßàÂô®Ëá™Âä®Âåñ | `mcp__playwright__*` | puppeteer |
| ÊñáÊ°£Êü•ËØ¢ | `mcp__context7__query-docs` | WebFetch |
| Âø´ÈÄüÊêúÁ¥¢ | `mcp__duckduckgo__search` | WebSearch |

### ‰ΩïÊó∂‰ΩøÁî® MCP vs ËÑöÊú¨

**‰ΩøÁî® MCP**Ôºö
- ‰∏ÄÊ¨°ÊÄßÊü•ËØ¢„ÄÅÂø´ÈÄüÈ™åËØÅ
- ‰∫§‰∫íÂºèÊï∞ÊçÆÊé¢Á¥¢
- ÁÆÄÂçïÁöÑ CRUD Êìç‰Ωú
- Êü•Áúã GitHub PR/Issue
- ÊäìÂèñÁΩëÈ°µÂÜÖÂÆπ

**‰ΩøÁî®ËÑöÊú¨**Ôºö
- ÊâπÈáèÊï∞ÊçÆÂ§ÑÁêÜÔºà100+ Êù°ËÆ∞ÂΩïÔºâ
- ÈúÄË¶ÅÂ§çÊùÇ‰∏öÂä°ÈÄªËæë
- ÈúÄË¶Å‰∫ãÂä°ÊàñÈîôËØØÈáçËØï
- Áîü‰∫ßÁéØÂ¢ÉÂÆöÊó∂‰ªªÂä°

## ËÑöÊú¨ÊâßË°åÊúÄ‰Ω≥ÂÆûË∑µ

### ÈÅøÂÖç "Prompt is too long" ÈîôËØØ

ÈïøÊó∂Èó¥ËøêË°åÁöÑËÑöÊú¨ÂèØËÉΩ‰∫ßÁîüÂ§ßÈáèËæìÂá∫ÔºåÂØºËá¥ Claude Code ‰∏ä‰∏ãÊñáË∂ÖÈôê„ÄÇËß£ÂÜ≥ÊñπÊ≥ïÔºö

**1. ‰ΩøÁî® `--quiet` Ê®°Âºè**
```bash
npx tsx scripts/enrich/xxx.ts --quiet
```
ËÑöÊú¨Â∫îÊîØÊåÅÈùôÈªòÊ®°ÂºèÔºåÂè™ËæìÂá∫ËøõÂ∫¶ÊëòË¶ÅÂíåÊúÄÁªàÁªüËÆ°„ÄÇ

**2. ËøáÊª§ Prisma debug Êó•Âøó**
```bash
npx tsx scripts/xxx.ts 2>&1 | grep -v "^prisma:"
```

**3. ËæìÂá∫ÈáçÂÆöÂêëÂà∞Êñá‰ª∂**
```bash
npx tsx scripts/xxx.ts > /tmp/output.log 2>&1
tail -50 /tmp/output.log  # Âè™Êü•ÁúãÊúÄÂêéÈÉ®ÂàÜ
```

**4. ÂàÜÊâπÂ§ÑÁêÜ**
```bash
npx tsx scripts/xxx.ts --limit=50  # ÊØèÊ¨°Âè™Â§ÑÁêÜ50Êù°
```

**5. ËÑöÊú¨ÁºñÂÜôËßÑËåÉ**
```typescript
const quiet = args.includes('--quiet');
const log = (msg: string) => { if (!quiet) console.log(msg); };

// ÈùôÈªòÊ®°Âºè‰∏ãÊØè N Êù°ËæìÂá∫‰∏ÄÊ¨°ËøõÂ∫¶
if (quiet && i % 20 === 0) console.log(`ËøõÂ∫¶: ${i}/${total}`);

// ÊúÄÁªàÁªüËÆ°ÂßãÁªàËæìÂá∫
console.log(`üìä ÂÆåÊàê: Â§ÑÁêÜ ${total} Êù°ÔºåÊàêÂäü ${success} Êù°`);
```

## Documentation
- `PROJECT_CONSTITUTION.md` - Architecture, deployment, error book
- `workflow_documentation.md` - Data flows, APIs, KPIs
- `README.md` - Setup guide (Chinese)
